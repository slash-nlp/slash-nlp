---
sidebar_label: "Tokenization"
sidebar_position: 0
---

# Tokenization

Tokenization is a method of tagging the words in a corpus or dataset with numbers. The total tokenized collection is called a **word index**, which is a dictionary mapping words to numbers.

In ML/DL models, tokenization is an _essential_ processing techniques used for preprocessing datatsets as learning models generally deal with models that take numerical input.

## Google Colab

```
https://goo.gle/2uO6Gee
```

import YouTube from "react-youtube";

<YouTube videoId="fNxaJsNG3-s" />
